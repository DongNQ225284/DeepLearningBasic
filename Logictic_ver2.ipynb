{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giới thiệu về Neuralnetwork\n",
    "\n",
    "NeuralNetwork là mạng thần kinh, gồm nhiều layer, với mỗi layer có nhiều neuron, phần tử neuron là phần tử nhỏ nhất trong mạng và nó được lấy cảm hứng từ cách hoạt động của neuron của con người  \n",
    "\n",
    "Dưới đây là bài toán phân loại được phát biểu giống với ver1, tuy nhiên cách tổ chức code theo hướng đối tượng  \n",
    "\n",
    "NeuralNetwork được sinh ra với mục đích là giống với bài toán phân loại, nhưng nó sẽ giải quyết được nhiều bài toán mà Logictic không thể giải quyết được (Ví dụ: Bài toán XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    def sigmoid(x):\n",
    "        return 1.0/(1 + np.exp(-x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_function:\n",
    "    def BCE(y_predict, y_true):\n",
    "        return - (y_true * np.log(y_predict) + (1 - y_true) * np.log(1 - y_predict))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, input_size):\n",
    "        self.bias = 1.0\n",
    "        self.w = np.full(input_size, 1.0).reshape(-1, 1)\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = Activation.sigmoid(input @ self.w + self.bias)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, alpha, target):\n",
    "        dL_dz = self.output - target\n",
    "        dL_dw = self.input.T @ dL_dz\n",
    "        dL_db = np.sum(dL_dz)\n",
    "\n",
    "        self.w -= alpha * dL_dw\n",
    "        self.bias -= alpha * dL_db\n",
    "\n",
    "    def show(self):\n",
    "        print(f\"w: {self.w}\")\n",
    "        print(f\"bias: {self.bias}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, input_size, learning_rate = 0.0005):\n",
    "        self.alpha = learning_rate\n",
    "        self.neuron = Neuron(input_size)\n",
    "        self.history = []\n",
    "        self.loss = None\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.neuron.forward(input)\n",
    "        return self.neuron.output\n",
    "\n",
    "    def backward(self, target):\n",
    "        self.neuron.backward(self.alpha, target)\n",
    "        \n",
    "    def train(self, dataset, max_iter):\n",
    "        x = dataset[:, :-1]\n",
    "        y_true = dataset[:, -1].reshape(-1, 1)\n",
    "    \n",
    "        for i in range(max_iter):\n",
    "            y_predict = self.forward(x)\n",
    "            self.loss = Loss_function.BCE(y_predict, y_true)\n",
    "            self.history.append(self.loss)\n",
    "            self.backward(y_true)\n",
    "\n",
    "            #print(f\"Generation {i}:\")\n",
    "            #print(y_predict)\n",
    "\n",
    "    def show(self):\n",
    "        self.neuron.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [[0.21811212]\n",
      " [0.91734034]]\n",
      "bias: -3.0868121445172347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.47086329],\n",
       "       [0.18017897],\n",
       "       [0.30663313],\n",
       "       [0.40620336],\n",
       "       [0.87392458],\n",
       "       [0.77502144],\n",
       "       [0.84199   ],\n",
       "       [0.68043453]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.array([[1, 3, 0], [3, 1, 0], [2, 2, 0], [4, 2, 0],\n",
    "                    [2, 5, 1], [3, 4, 1], [5, 4, 1], [5, 3, 1]])\n",
    "\n",
    "x = dataset[:, :-1]\n",
    "model = Model(2)\n",
    "model.train(dataset, 10000)\n",
    "model.show()\n",
    "model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99330715]\n",
      " [0.99330715]\n",
      " [0.99330715]\n",
      " [0.99908895]\n",
      " [0.99966465]\n",
      " [0.99966465]\n",
      " [0.9999546 ]\n",
      " [0.99987661]]\n",
      "w: [[0.99900463]\n",
      " [0.99920455]]\n",
      "bias: 0.9996021829096673\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = dataset[:, :-1]\n",
    "y_true = dataset[:, -1].reshape(-1, 1)\n",
    "neuron = Neuron(2)\n",
    "y_pre = neuron.forward(x)\n",
    "neuron.backward(0.0001, y_true)\n",
    "print(y_pre)\n",
    "neuron.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
